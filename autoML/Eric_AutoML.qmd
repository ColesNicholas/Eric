---
title: "Eric_AutoML.qmd"
author: "Nicholas a. Coles"
format: html
editor_options: 
  chunk_output_type: console
---

# load libraries and data
```{r}
# time series autoML
library(h2o)
library(iForecast)
library(zoo)
library(slider)

# data processing
library(tidyverse)
library(readxl)
```

# open data and specify variable classes
```{r}
data_r <- read_xlsx('PJMdatatest1.xlsx') %>%

  # remove extra date variables (but keep month)
  select(-c('Date', 'Day', 'Year', 'Days Back')) %>%
  
  # remove leakage variables
  select(-c('RT LMP', 
            'DA/L-AVG' : 'GB/NLA'
            )) %>%

  # convert to time series structure
  mutate(time = as.Date(`Date/Time`)) %>%
  select(-`Date/Time`) %>%
  arrange(time) %>%

  # rename main dv
  rename('DA_LMP' = 'DA LMP')
```

# Prepare to train
Specify target and exogenous predictors
```{r}
y_zoo <- zoo(data_r$`DA_LMP`,
             order.by = data_r$time)

x_zoo <- data_r[, 
                setdiff(colnames(data_r), 
                        c("time", "DA_LMP")),
                drop = FALSE] %>% 
  zoo(x = .,
      order.by = data_r$time)
```

specify training end and initialize h20
```{r}
train.end <- "2025-10-31"

h2o.init(max_mem_size = "8g")
```

# Train
```{r}
automl <- 
  tts.autoML(y = y_zoo,
             x = x_zoo,
             train.end = train.end,
             arOrder   = c(1, 2, 7),   # 1, 2, 7 day lag of y
             xregOrder = c(0, 1, 2, 7), # 0, 1, 2, 7 day lag of x
             type = 'none', # stupid setting
             initial = F) # don't autoinitialize
```

# Inspect model behavior
```{r}
# leaderboard
automl$modelsUsed %>% print()

# feature reliance
h2o.varimp_heatmap(object = automl$modelsUsed, 
                   top_n = 10, 
                   num_of_features = 20)
```

# Out of sample prediction error
create out-of-sample evaluation function
```{r}
EvalFun <- function(m){
  
  # compile test data
  testData2 <- 
    window(automl$dataused,
           start = "2025-10-31",
           end = end(automl$data))
  
  # predict out of sample using favorite model
  preds <- 
    h2o.predict(m, 
                as.h2o(testData2)) %>% 
    as.data.frame()
  
  # evaluate out-of-sample error
  eval <-
    # join dataset
    cbind(testData2, preds) %>% 
    as.data.frame() %>% 
    
    # calculate error
    rowwise() %>% 
    mutate(abs_error = abs(y - predict)) %>% 
    ungroup()
  
  return(eval)
}
```

## Evaluate model 4: GBM_grid_1
```{r}
m4.eval <-
  lb$model_id[4] %>% 
  as.vector() %>% 
  h2o.getModel() %>% 
  EvalFun

# view output 
View(m4.eval)

# average wrongness (MAE)
mean(m4.eval$abs_error)

# insight: more wrong at high prices
plot(m4.eval$y,
     m4.eval$abs_error)

# average wrongness during normal times
m4.eval[m4.eval$y < 100, ]$abs_error %>% mean()

m4.eval[m4.eval$y < 80, ]$abs_error %>% mean()
  
```

## Evaluate model 6
Evaluate model 6: DeepLearning_grid_1_AutoML_2_20251217_161026_model_2
```{r}
h2o.varimp_heatmap(object = automl$modelsUsed, 
                   top_n = 10, 
                   num_of_features = 20)

m6.eval <-
  lb$model_id[6] %>% 
  as.vector() %>% 
  h2o.getModel() %>% 
  EvalFun

# view output 
m6.eval %>% 
  select(y, predict, abs_error) %>% 
  View()

# average wrongness (MAE)
mean(m6.eval$abs_error)

# insight: more wrong at high prices
plot(m6.eval$y,
     m6.eval$abs_error)

# average wrongness during normal times
m6.eval[m6.eval$y < 100, ]$abs_error %>% mean()

m6.eval[m6.eval$y < 80, ]$abs_error %>% mean()
```

## Evaluate model 7
Evaluate model 7: DeepLearning_grid_1_AutoML_2_20251217_161026_model_2
```{r}
h2o.varimp_heatmap(object = automl$modelsUsed, 
                   top_n = 10, 
                   num_of_features = 20)

m7.eval <-
  lb$model_id[7] %>% 
  as.vector() %>% 
  h2o.getModel() %>% 
  EvalFun

# average wrongness (MAE)
mean(m7.eval$abs_error)

# insight: especially tight at low prices
plot(m7.eval$y,
     m7.eval$abs_error)

# average wrongness during normal times
m7.eval[m7.eval$y < 100, ]$abs_error %>% mean()

m7.eval[m7.eval$y < 80, ]$abs_error %>% mean()
```

## Evaluate best ensemble (cue nail bite)
Details about the ensemble
```{r}
automl$output
```

```{r}
m1.eval <-
  automl$output %>% 
  EvalFun

# average wrongness (MAE)
mean(m1.eval$abs_error)

# insight: especially tight at low prices
plot(m1.eval$y,
     m1.eval$abs_error)

# average wrongness during normal times
m1.eval[m1.eval$y < 100, ]$abs_error %>% mean()

m1.eval[m1.eval$y < 80, ]$abs_error %>% mean()

automl$output
```
