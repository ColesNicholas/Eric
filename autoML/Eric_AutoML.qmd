---
title: "Eric_AutoML.qmd"
author: "Nicholas a. Coles"
format: html
editor_options: 
  chunk_output_type: console
---
# load libraries and data
```{r}
# time series autoML
library(h2o)
library(iForecast)
library(zoo)
library(slider)

# data processing
library(tidyverse)
library(readxl)
library(DataExplorer)
```

# open data and specify variable classes
```{r}
data_r <- read_xlsx('PJMdatatest1.xlsx') %>%

  # remove extra date variables (but keep month)
  select(-c('Date', 'Day', 'Year', 'Days Back')) %>%
  
  # remove leakage variables
  select(-c('RT LMP', 
            'DA/L-AVG' : 'GB/NLA'
            )) %>%

  # convert to time series structure
  mutate(time = as.Date(`Date/Time`)) %>%
  select(-`Date/Time`) %>%
  arrange(time) %>%

  # rename main dv
  rename('DA_LMP' = 'DA LMP')
```

# Prepare to train
Specify target and exogenous predictors
```{r}
y_zoo <- zoo(data_r$`DA_LMP`,
             order.by = data_r$time)

x_zoo <- data_r[, 
                setdiff(colnames(data_r), 
                        c("time", "DA_LMP")),
                drop = FALSE] %>% 
  zoo(x = .,
      order.by = data_r$time)

setdiff(colnames(data_r), 
        c("time", "DA_LMP"))
```

specify training end and initialize h20
```{r}
train.end <- "2025-10-31"

h2o.init(max_mem_size = "8g")
```

# Train
```{r}
automl <- 
  tts.autoML(y = y_zoo,
             x = x_zoo,
             train.end = train.end,
             arOrder   = c(1, 2, 7),   # 1, 2, 7 day lag of y
             xregOrder = c(0, 1, 2, 7), # 0, 1, 2, 7 day lag of x
             type = 'none', # stupid setting
             initial = F) # don't autoinitialize
```

# Inspect model behavior
```{r}
# leaderboard
# an average, $4-5 off. But this is too conservative due to likely leakage during CV folding
lb <- automl$modelsUsed

# feature reliance
h2o.varimp_heatmap(object = automl$modelsUsed, 
                   top_n = 10, 
                   num_of_features = 20)
```

# Out of sample prediction error
create out-of-sample evaluation function

Reminder: stopped training "2025-10-31"
automl$train.end

tmp <- lb$model_id[4] %>% 
  as.vector() %>% 
  h2o.getModel
  
tmp@parameters$training_frame %>% h2o.getFrame() %>% as.data.frame() %>% View()

```{r}
EvalFun <- function(m){
  
  # compile test data it's never seen
  testData2 <- 
    window(automl$dataused,
           start = "2025-10-31",
           end = end(automl$data))
  
  # predict out of sample using favorite model
  preds <- 
    h2o.predict(m, 
                as.h2o(testData2)) %>% 
    as.data.frame()
  
  # evaluate out-of-sample error
  eval <-
    # join dataset
    cbind(testData2, preds) %>% 
    as.data.frame() %>% 
    
    # calculate error
    rowwise() %>% 
    mutate(abs_error = abs(y - predict)) %>% 
    ungroup()
  
  return(eval)
}
```

## Evaluate model 5: GBM_grid_1
```{r}
m5.eval <-
  lb$model_id[5] %>% 
  as.vector() %>% 
  h2o.getModel() %>% 
  EvalFun

# view full output 
View(m5.eval)

# average wrongness (MAE)
mean(m5.eval$abs_error)

# insight: more wrong at high prices
plot(m5.eval$y,
     m5.eval$abs_error)

# average wrongness during normal times
m5.eval[m5.eval$y < 100, ]$abs_error %>% mean()

m5.eval[m5.eval$y < 80, ]$abs_error %>% mean()
```

## Evaluate model 3
Evaluate model 3: DeepLearning_grid_1_AutoML_3_20251217_194536_model_1
```{r}
h2o.varimp_heatmap(object = automl$modelsUsed, 
                   top_n = 10, 
                   num_of_features = 20)

m3.eval <-
  lb$model_id[3] %>% 
  as.vector() %>% 
  h2o.getModel() %>% 
  EvalFun

# view output 
m3.eval %>% 
  select(y, predict, abs_error) %>% 
  View()

# average wrongness (MAE)
mean(m3.eval$abs_error)

# insight: better at low prices, just as bad at high prices
plot(m3.eval$y,
     m3.eval$abs_error)

# average wrongness during normal times
m3.eval[m3.eval$y < 100, ]$abs_error %>% mean()

m3.eval[m3.eval$y < 80, ]$abs_error %>% mean()
```

## Evaluate best ensemble (cue nail bite)
Details about the ensemble
```{r}
automl$output
```

```{r}
m1.eval <-
  automl$output %>% 
  EvalFun

# average wrongness (MAE)
mean(m1.eval$abs_error)

# insight: especially tight at low prices
plot(m1.eval$y,
     m1.eval$abs_error)

# average wrongness during normal times
m1.eval[m1.eval$y < 100, ]$abs_error %>% mean()

m1.eval[m1.eval$y < 80, ]$abs_error %>% mean()

automl$output
```

## What do we know about the days where the models do well?
```{r}
data_r %>% 
  filter(time > train.end,
         DA_LMP < 80) %>% 
  create_report()
```

## How does this fare compared to a baseline?
```{r}
b.eval <- testData2 %>% 
  as.data.frame() %>% 
  select(y, ar1) %>% 
  rowwise() %>% 
  mutate(abs_error = abs(y - ar1)) %>% 
  ungroup()

# average wrongness (MAE)
mean(b.eval$abs_error, 
     na.rm = T)

mean(m1.eval$abs_error, 
     na.rm = T)

# insight: especially tight at low prices
plot(b.eval$y,
     b.eval$abs_error)

# average wrongness during normal times
b.eval[b.eval$y < 100, ]$abs_error %>% mean()
m1.eval[m1.eval$y < 100, ]$abs_error %>% mean()

b.eval[m1.eval$y < 80, ]$abs_error %>% mean()
m1.eval[m1.eval$y < 80, ]$abs_error %>% mean()

automl$output
```

